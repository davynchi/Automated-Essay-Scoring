{
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": [],
   "authorship_tag": "ABX9TyOknaJxkYrbW4bzIHtMOBF+"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "4536522035ed40f0a80c0cb1fd317571": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0249b329fa5c4e988bec68f56b712bf3",
       "IPY_MODEL_1b5eb38d8fcf47d480b0142675c81be3",
       "IPY_MODEL_414745debe7b492a84a4e1873969d5a2"
      ],
      "layout": "IPY_MODEL_3ee784f9b9b64b46aac495647ba9940e"
     }
    },
    "0249b329fa5c4e988bec68f56b712bf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13db27eb39e54bb4b39bdb59cda4df6c",
      "placeholder": "​",
      "style": "IPY_MODEL_7b0de6bbb7954791ac51db4b1538a61e",
      "value": "config.json: 100%"
     }
    },
    "1b5eb38d8fcf47d480b0142675c81be3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f662b2c5b8a84908b3522b4a590e53a2",
      "max": 579,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a47c3aad1f95417babbe660bb520e543",
      "value": 579
     }
    },
    "414745debe7b492a84a4e1873969d5a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6021d5cde0124e4b936ac99094cc603f",
      "placeholder": "​",
      "style": "IPY_MODEL_74acc7a20f02455aaee2294398f66b75",
      "value": " 579/579 [00:00&lt;00:00, 32.4kB/s]"
     }
    },
    "3ee784f9b9b64b46aac495647ba9940e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13db27eb39e54bb4b39bdb59cda4df6c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b0de6bbb7954791ac51db4b1538a61e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f662b2c5b8a84908b3522b4a590e53a2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a47c3aad1f95417babbe660bb520e543": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6021d5cde0124e4b936ac99094cc603f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74acc7a20f02455aaee2294398f66b75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 71485,
     "databundleVersionId": 8059942,
     "sourceType": "competition"
    },
    {
     "sourceId": 8944399,
     "sourceType": "datasetVersion",
     "datasetId": 5382221
    },
    {
     "sourceId": 173941580,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Directory Setting",
   "metadata": {
    "id": "uPMNzgkAYC5X"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "\n",
    "INPUT_DIR = \"/kaggle/input/aes2-train-data/\"\n",
    "OOF_DIR = \"\"\n",
    "MLM_PATH = \"/kaggle/input/lal-deberta-base-mlm/deberta_v3_base_chk/checkpoint-57824/\"\n",
    "OUTPUT_DIR = \"/kaggle/working/\"\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ],
   "metadata": {
    "executionInfo": {
     "elapsed": 2102,
     "status": "ok",
     "timestamp": 1714100402475,
     "user": {
      "displayName": "落合広則",
      "userId": "03558466850887896673"
     },
     "user_tz": -540
    },
    "id": "RW60b39ZNtqq",
    "execution": {
     "iopub.status.busy": "2024-07-14T01:52:25.175725Z",
     "iopub.execute_input": "2024-07-14T01:52:25.176053Z",
     "iopub.status.idle": "2024-07-14T01:52:25.188912Z",
     "shell.execute_reply.started": "2024-07-14T01:52:25.176028Z",
     "shell.execute_reply": "2024-07-14T01:52:25.18778Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# CFG",
   "metadata": {
    "id": "2HvfxeCPYHfd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "\n",
    "\n",
    "class CFG:\n",
    "    debug = False\n",
    "    apex = True\n",
    "    print_freq = 100\n",
    "    num_workers = 4\n",
    "    model = \"microsoft/deberta-v3-base\"\n",
    "    scheduler = \"cosine\"  # ['linear', 'cosine']\n",
    "    batch_scheduler = True\n",
    "    num_cycles = 0.5\n",
    "    num_warmup_steps = 0\n",
    "    epochs = 5\n",
    "    encoder_lr = 1e-5\n",
    "    decoder_lr = 1e-5\n",
    "    min_lr = 1e-6\n",
    "    eps = 1e-6\n",
    "    betas = (0.9, 0.999)\n",
    "    batch_size = 2\n",
    "    fc_dropout = 0.0\n",
    "    model_config = {\n",
    "        \"attention_dropout\": 0.0,\n",
    "        \"attention_probs_dropout_prob\": 0.0,\n",
    "        \"hidden_dropout\": 0.0,\n",
    "        \"hidden_dropout_prob\": 0.0,\n",
    "        #'layer_norm_eps':1e-7,\n",
    "    }\n",
    "    target_size = 1\n",
    "    target_cols = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "    target_cols2 = [\"score\"]\n",
    "    target_cols3 = [\"score_s\"]\n",
    "    max_len = 1024\n",
    "    weight_decay = 0.01\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "    seed = 42\n",
    "    n_fold = 6\n",
    "    # trn_fold=[0, 1, 2, 3]\n",
    "    trn_fold = [0]\n",
    "    freeze_layer = 9\n",
    "    head = \"mean_pooling\"  #'mean_pooling' 'attention' 'lstm'\n",
    "    sl = False\n",
    "    sl_rate = 0.2\n",
    "    train = True\n",
    "    flag = 0"
   ],
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1714100402476,
     "user": {
      "displayName": "落合広則",
      "userId": "03558466850887896673"
     },
     "user_tz": -540
    },
    "id": "wqUvdbxBNzwl",
    "execution": {
     "iopub.status.busy": "2024-07-14T01:56:59.137559Z",
     "iopub.execute_input": "2024-07-14T01:56:59.137954Z",
     "iopub.status.idle": "2024-07-14T01:56:59.146383Z",
     "shell.execute_reply.started": "2024-07-14T01:56:59.137919Z",
     "shell.execute_reply": "2024-07-14T01:56:59.14535Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Library",
   "metadata": {
    "id": "yT7ZllFPYMnu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece"
   ],
   "metadata": {
    "executionInfo": {
     "elapsed": 11935,
     "status": "ok",
     "timestamp": 1714100414408,
     "user": {
      "displayName": "落合広則",
      "userId": "03558466850887896673"
     },
     "user_tz": -540
    },
    "id": "kyfDDI38OzZl",
    "outputId": "d80d2ac9-bae6-4c2b-8985-7dd85e522923",
    "execution": {
     "iopub.status.busy": "2024-07-14T01:52:25.204404Z",
     "iopub.execute_input": "2024-07-14T01:52:25.205868Z",
     "iopub.status.idle": "2024-07-14T01:52:51.126465Z",
     "shell.execute_reply.started": "2024-07-14T01:52:25.205842Z",
     "shell.execute_reply": "2024-07-14T01:52:51.125359Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import ast\n",
    "import copy\n",
    "import gc\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "\n",
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import joblib\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "# os.system('pip uninstall -y transformers')\n",
    "# os.system('python -m pip install --no-index --find-links=../input/nbme-pip-wheels transformers')\n",
    "import tokenizers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from sklearn.metrics import cohen_kappa_score, f1_score, log_loss, mean_squared_error\n",
    "from sklearn.model_selection import (\n",
    "    GroupKFold,\n",
    "    KFold,\n",
    "    StratifiedGroupKFold,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "from torch.nn import Parameter\n",
    "from torch.optim import SGD, Adam, AdamW\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "executionInfo": {
     "elapsed": 14821,
     "status": "ok",
     "timestamp": 1714100429224,
     "user": {
      "displayName": "落合広則",
      "userId": "03558466850887896673"
     },
     "user_tz": -540
    },
    "id": "vW0_bB3BOAsy",
    "outputId": "99ae7b53-9949-491d-d216-98e8f425246c",
    "execution": {
     "iopub.status.busy": "2024-07-14T01:52:51.128795Z",
     "iopub.execute_input": "2024-07-14T01:52:51.129553Z",
     "iopub.status.idle": "2024-07-14T01:53:08.056646Z",
     "shell.execute_reply.started": "2024-07-14T01:52:51.129514Z",
     "shell.execute_reply": "2024-07-14T01:53:08.055673Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Utils",
   "metadata": {
    "id": "dxne9zQEYRpD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "\n",
    "\n",
    "def get_score(y_trues, y_preds):\n",
    "    y_preds = pd.cut(\n",
    "        y_preds.reshape(-1) * 5,\n",
    "        [-np.inf, 0.83333333, 1.66666667, 2.5, 3.33333333, 4.16666667, np.inf],\n",
    "        labels=[0, 1, 2, 3, 4, 5],\n",
    "    )\n",
    "    score = cohen_kappa_score(y_trues, y_preds, weights=\"quadratic\")\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_logger(filename=OUTPUT_DIR + \"train\"):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_everything(seed=CFG.seed)"
   ],
   "metadata": {
    "executionInfo": {
     "elapsed": 720,
     "status": "ok",
     "timestamp": 1714100429940,
     "user": {
      "displayName": "落合広則",
      "userId": "03558466850887896673"
     },
     "user_tz": -540
    },
    "id": "e7ep4QmkSb7Q",
    "execution": {
     "iopub.status.busy": "2024-07-14T01:53:08.057986Z",
     "iopub.execute_input": "2024-07-14T01:53:08.05853Z",
     "iopub.status.idle": "2024-07-14T01:53:08.071874Z",
     "shell.execute_reply.started": "2024-07-14T01:53:08.058502Z",
     "shell.execute_reply": "2024-07-14T01:53:08.070672Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#Dats Loading",
   "metadata": {
    "id": "n6TK1jBfYVdY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ====================================================\n",
    "# Data Loading\n",
    "# ====================================================\n",
    "train = pd.read_pickle(f\"{INPUT_DIR}train.pkl\")\n",
    "if CFG.sl:\n",
    "    oof = pd.read_pickle(f\"{OOF_DIR}oof_df.pkl\")\n",
    "    train = train.merge(oof[[\"essay_id\", \"pred\"]], on=\"essay_id\", how=\"left\")\n",
    "    train[CFG.target_cols3[0]] = (\n",
    "        (train[CFG.target_cols2[0]].values / 5) * (1 - CFG.sl_rate)\n",
    "    ) + (train[\"pred\"].values * CFG.sl_rate)\n",
    "else:\n",
    "    train[CFG.target_cols3[0]] = train[CFG.target_cols2[0]].values / 5\n",
    "print(train.shape)\n",
    "train.head()"
   ],
   "metadata": {
    "executionInfo": {
     "elapsed": 4807,
     "status": "ok",
     "timestamp": 1714100434744,
     "user": {
      "displayName": "落合広則",
      "userId": "03558466850887896673"
     },
     "user_tz": -540
    },
    "id": "mE-TWK3aOrc7",
    "outputId": "21c915b0-2347-45f3-f774-af06624382d5",
    "execution": {
     "iopub.status.busy": "2024-07-14T01:53:08.075282Z",
     "iopub.execute_input": "2024-07-14T01:53:08.076089Z",
     "iopub.status.idle": "2024-07-14T01:53:08.879332Z",
     "shell.execute_reply.started": "2024-07-14T01:53:08.076017Z",
     "shell.execute_reply": "2024-07-14T01:53:08.878463Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Tokenizer",
   "metadata": {
    "id": "5cPsbd-GYcPl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ====================================================\n",
    "# tokenizer\n",
    "# ====================================================\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": [\"[BR]\"]})\n",
    "CFG.tokenizer = tokenizer"
   ],
   "metadata": {
    "executionInfo": {
     "elapsed": 5585,
     "status": "ok",
     "timestamp": 1714100440325,
     "user": {
      "displayName": "落合広則",
      "userId": "03558466850887896673"
     },
     "user_tz": -540
    },
    "id": "V-a6s_KnPXJp",
    "execution": {
     "iopub.status.busy": "2024-07-14T01:57:21.164961Z",
     "iopub.execute_input": "2024-07-14T01:57:21.166003Z",
     "iopub.status.idle": "2024-07-14T01:57:22.560544Z",
     "shell.execute_reply.started": "2024-07-14T01:57:21.16596Z",
     "shell.execute_reply": "2024-07-14T01:57:22.55954Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.hist(train[\"length\"])\n",
    "plt.show()"
   ],
   "metadata": {
    "executionInfo": {
     "elapsed": 696,
     "status": "ok",
     "timestamp": 1714100441005,
     "user": {
      "displayName": "落合広則",
      "userId": "03558466850887896673"
     },
     "user_tz": -540
    },
    "id": "MoCWP3foHMRf",
    "outputId": "2e55e9ae-e7fe-494c-b353-f4b5c935a2d5",
    "execution": {
     "iopub.status.busy": "2024-07-14T01:53:11.693806Z",
     "iopub.execute_input": "2024-07-14T01:53:11.694765Z",
     "iopub.status.idle": "2024-07-14T01:53:11.961235Z",
     "shell.execute_reply.started": "2024-07-14T01:53:11.694713Z",
     "shell.execute_reply": "2024-07-14T01:53:11.960297Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# CV Split",
   "metadata": {
    "id": "85p7PDM-HJMv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install -q iterative-stratification\n",
    "# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "# Fold = MultilabelStratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "# for n, (train_index, val_index) in enumerate(Fold.split(train, train[['score', 'length']])):\n",
    "#    train.loc[val_index, 'fold'] = int(n)\n",
    "# train['fold'] = train['fold'].astype(int)\n",
    "display(train.groupby(\"fold\").size())"
   ],
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1714100441005,
     "user": {
      "displayName": "落合広則",
      "userId": "03558466850887896673"
     },
     "user_tz": -540
    },
    "id": "hX_7QMIZHLR7",
    "outputId": "e4754311-a3a4-4e2e-fdea-ef50b4a22049",
    "execution": {
     "iopub.status.busy": "2024-07-14T01:53:11.962311Z",
     "iopub.execute_input": "2024-07-14T01:53:11.962583Z",
     "iopub.status.idle": "2024-07-14T01:53:11.973965Z",
     "shell.execute_reply.started": "2024-07-14T01:53:11.962558Z",
     "shell.execute_reply": "2024-07-14T01:53:11.973035Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Dataset",
   "metadata": {
    "id": "olRaGjhjYhLL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def prepare_input(cfg, text):\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text,\n",
    "        return_tensors=None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=CFG.max_len,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df[\"full_text\"].values\n",
    "        self.labels = df[cfg.target_cols2].values\n",
    "        self.labels2 = df[cfg.target_cols3].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, self.texts[item])\n",
    "        label = torch.tensor(self.labels[item], dtype=torch.float)\n",
    "        label2 = torch.tensor(self.labels2[item], dtype=torch.float)\n",
    "        return inputs, label, label2\n",
    "\n",
    "\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:, :mask_len]\n",
    "    return inputs"
   ],
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1714100441005,
     "user": {
      "displayName": "落合広則",
      "userId": "03558466850887896673"
     },
     "user_tz": -540
    },
    "id": "8b-5D8zBPd6f",
    "execution": {
     "iopub.status.busy": "2024-07-14T01:53:11.975141Z",
     "iopub.execute_input": "2024-07-14T01:53:11.975463Z",
     "iopub.status.idle": "2024-07-14T01:53:11.985569Z",
     "shell.execute_reply.started": "2024-07-14T01:53:11.975438Z",
     "shell.execute_reply": "2024-07-14T01:53:11.98465Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Model",
   "metadata": {
    "id": "w-y-WBdyYnEd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "\n",
    "\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = (\n",
    "            attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        )\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "\n",
    "class CustomModel_mean_pooling(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        self.config.update(CFG.model_config)\n",
    "        if cfg.sl:\n",
    "            if pretrained:\n",
    "                self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "            else:\n",
    "                self.model = AutoModel.from_config(self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_pretrained(MLM_PATH)\n",
    "        self.model.gradient_checkpointing_enable()\n",
    "        self.pool = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n",
    "        self._init_weights(self.fc)\n",
    "        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n",
    "        self.model.embeddings.requires_grad_(False)\n",
    "        self.model.encoder.layer[: CFG.freeze_layer].requires_grad_(False)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        feature = self.pool(last_hidden_states, inputs[\"attention_mask\"])\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        feature = self.layer_norm1(feature)\n",
    "        output = self.fc(feature)\n",
    "        return output\n",
    "\n",
    "\n",
    "class CustomModel_attention(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        self.config.update(cfg.model_config)\n",
    "        if cfg.sl:\n",
    "            if pretrained:\n",
    "                self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "            else:\n",
    "                self.model = AutoModel.from_config(self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_pretrained(MLM_PATH)\n",
    "        self.model.gradient_checkpointing_enable()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n",
    "        self._init_weights(self.fc)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.config.hidden_size, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "        self._init_weights(self.attention)\n",
    "        self.model.embeddings.requires_grad_(False)\n",
    "        self.model.encoder.layer[: CFG.freeze_layer].requires_grad_(False)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        weights = self.attention(last_hidden_states)\n",
    "        feature = torch.sum(weights * last_hidden_states, dim=1)\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(feature)\n",
    "        return output\n",
    "\n",
    "\n",
    "class CustomModel_lstm(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        self.config.update(cfg.model_config)\n",
    "        if cfg.sl:\n",
    "            if pretrained:\n",
    "                self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "            else:\n",
    "                self.model = AutoModel.from_config(self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_pretrained(MLM_PATH)\n",
    "        self.model.gradient_checkpointing_enable()\n",
    "        self.pool = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n",
    "        self._init_weights(self.fc)\n",
    "        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n",
    "        self.lstm = nn.LSTM(\n",
    "            self.config.hidden_size,\n",
    "            (self.config.hidden_size) // 2,\n",
    "            num_layers=2,\n",
    "            dropout=self.config.hidden_dropout_prob,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self._init_weights(self.lstm)\n",
    "        self.model.embeddings.requires_grad_(False)\n",
    "        self.model.encoder.layer[: CFG.freeze_layer].requires_grad_(False)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        feature, hc = self.lstm(last_hidden_states)\n",
    "        feature = self.pool(feature, inputs[\"attention_mask\"])\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        feature = self.layer_norm1(feature)\n",
    "        output = self.fc(feature)\n",
    "        return output"
   ],
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1714100540294,
     "user": {
      "displayName": "落合広則",
      "userId": "03558466850887896673"
     },
     "user_tz": -540
    },
    "id": "srFuA4fCTivC",
    "execution": {
     "iopub.status.busy": "2024-07-14T01:53:11.986842Z",
     "iopub.execute_input": "2024-07-14T01:53:11.98712Z",
     "iopub.status.idle": "2024-07-14T01:53:12.024646Z",
     "shell.execute_reply.started": "2024-07-14T01:53:11.987096Z",
     "shell.execute_reply": "2024-07-14T01:53:12.023517Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Helper functions",
   "metadata": {
    "id": "VqN7k66qYqdi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(\n",
    "    fold,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    valid_labels,\n",
    "    valid_loader2,\n",
    "    valid_labels2,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epoch,\n",
    "    scheduler,\n",
    "    device,\n",
    "    best_score,\n",
    "):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    preds = []\n",
    "    train_labels = []\n",
    "    for step, (inputs, labels, labels2) in enumerate(train_loader):\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            inputs = collate(inputs)\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels2 = labels2.to(device)\n",
    "            batch_size = labels.size(0)\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds, labels2)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.sigmoid().detach().to(\"cpu\").numpy())\n",
    "        train_labels.append(labels.detach().to(\"cpu\").numpy())\n",
    "        scaler.scale(loss).backward()\n",
    "        # awp.attack_backward(inputs, labels, epoch)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % (CFG.print_freq * CFG.gradient_accumulation_steps) == 0 or step == (\n",
    "            len(train_loader) - 1\n",
    "        ):\n",
    "            print(\n",
    "                \"Epoch: [{0}][{1}/{2}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                \"LR: {lr:.8f}  \".format(\n",
    "                    epoch + 1,\n",
    "                    step,\n",
    "                    len(train_loader),\n",
    "                    remain=timeSince(start, float(step + 1) / len(train_loader)),\n",
    "                    loss=losses,\n",
    "                    lr=scheduler.get_lr()[0],\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if step > len(train_loader) - 2:\n",
    "                predictions = np.concatenate(preds)\n",
    "                train_labels = np.concatenate(train_labels)\n",
    "                train_score = get_score(train_labels, predictions)\n",
    "                avg_val_loss, predictions, predictions2 = valid_fn(\n",
    "                    valid_loader, valid_loader2, model, criterion, device\n",
    "                )\n",
    "                score = get_score(valid_labels, predictions)\n",
    "                score2 = get_score(valid_labels2, predictions2)\n",
    "                elapsed = time.time() - start\n",
    "                LOGGER.info(\n",
    "                    f\"Epoch_Step {epoch+1}_{step} - avg_train_loss: {losses.avg:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n",
    "                )\n",
    "                LOGGER.info(\n",
    "                    f\"Epoch {epoch+1} - Train Score: {train_score:.4f} Val Score: {score:.4f} Val Score2: {score2:.4f}\"\n",
    "                )\n",
    "\n",
    "                if best_score < score2:\n",
    "                    best_score = score2\n",
    "                    LOGGER.info(\n",
    "                        f\"Epoch_Step {epoch+1}_{step} - Save Best Score: {best_score:.4f} Model\\n\"\n",
    "                    )\n",
    "                    torch.save(\n",
    "                        {\"model\": model.state_dict(), \"predictions\": predictions},\n",
    "                        OUTPUT_DIR + f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "                    )\n",
    "\n",
    "    return best_score\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, valid_loader2, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (inputs, labels, labels2) in enumerate(valid_loader):\n",
    "        with torch.no_grad():\n",
    "            inputs = collate(inputs)\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.to(device)\n",
    "            labels2 = labels2.to(device)\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds, labels2)\n",
    "        batch_size = labels2.size(0)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.sigmoid().to(\"cpu\").numpy())\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print(\n",
    "                \"EVAL: [{0}/{1}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \".format(\n",
    "                    step,\n",
    "                    len(valid_loader),\n",
    "                    loss=losses,\n",
    "                    remain=timeSince(start, float(step + 1) / len(valid_loader)),\n",
    "                )\n",
    "            )\n",
    "    predictions = np.concatenate(preds)\n",
    "\n",
    "    preds = []\n",
    "    for step, (inputs, labels, labels2) in enumerate(valid_loader2):\n",
    "        with torch.no_grad():\n",
    "            inputs = collate(inputs)\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.to(device)\n",
    "            labels2 = labels2.to(device)\n",
    "            y_preds = model(inputs)\n",
    "        batch_size = labels2.size(0)\n",
    "        preds.append(y_preds.sigmoid().to(\"cpu\").numpy())\n",
    "    predictions2 = np.concatenate(preds)\n",
    "\n",
    "    return losses.avg, predictions, predictions2"
   ],
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1714100540295,
     "user": {
      "displayName": "落合広則",
      "userId": "03558466850887896673"
     },
     "user_tz": -540
    },
    "id": "j6an-VG7Po-Z",
    "execution": {
     "iopub.status.busy": "2024-07-14T01:53:12.02809Z",
     "iopub.execute_input": "2024-07-14T01:53:12.028418Z",
     "iopub.status.idle": "2024-07-14T01:53:12.057563Z",
     "shell.execute_reply.started": "2024-07-14T01:53:12.028393Z",
     "shell.execute_reply": "2024-07-14T01:53:12.056639Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "\n",
    "\n",
    "def train_loop(folds, fold):\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    if CFG.flag == 0:\n",
    "        train_folds = folds[(folds[\"fold\"] != fold) & ((folds[\"flag\"] != 2))].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        valid_folds = folds[(folds[\"fold\"] == fold) & (folds[\"flag\"] != 2)].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        valid_folds2 = folds[(folds[\"fold\"] == fold) & (folds[\"flag\"] == 1)].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "    else:\n",
    "        train_folds = folds[(folds[\"fold\"] != fold) & ((folds[\"flag\"] == 1))].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        valid_folds = folds[(folds[\"fold\"] == fold) & (folds[\"flag\"] != 2)].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        valid_folds2 = folds[(folds[\"fold\"] == fold) & (folds[\"flag\"] == 0)].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "\n",
    "    valid_folds = valid_folds.sort_values([\"length\", \"essay_id\"]).reset_index(drop=True)\n",
    "    valid_labels = valid_folds[CFG.target_cols2].values\n",
    "    valid_folds2 = valid_folds2.sort_values([\"length\", \"essay_id\"]).reset_index(drop=True)\n",
    "    valid_labels2 = valid_folds2[CFG.target_cols2].values\n",
    "\n",
    "    train_dataset = TrainDataset(CFG, train_folds)\n",
    "    valid_dataset = TrainDataset(CFG, valid_folds)\n",
    "    valid_dataset2 = TrainDataset(CFG, valid_folds2)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    valid_loader2 = DataLoader(\n",
    "        valid_dataset2,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    if CFG.sl:\n",
    "        if CFG.head == \"mean_pooling\":\n",
    "            model = CustomModel_mean_pooling(CFG, config_path=None, pretrained=False)\n",
    "        elif CFG.head == \"attention\":\n",
    "            model = CustomModel_attention(CFG, config_path=None, pretrained=False)\n",
    "        elif CFG.head == \"lstm\":\n",
    "            model = CustomModel_lstm(CFG, config_path=None, pretrained=False)\n",
    "        state = torch.load(\n",
    "            \"/content/\" + f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "            map_location=torch.device(\"cpu\"),\n",
    "        )\n",
    "        model.load_state_dict(state[\"model\"])\n",
    "    else:\n",
    "        if CFG.head == \"mean_pooling\":\n",
    "            model = CustomModel_mean_pooling(CFG, config_path=None, pretrained=True)\n",
    "        elif CFG.head == \"attention\":\n",
    "            model = CustomModel_attention(CFG, config_path=None, pretrained=True)\n",
    "        elif CFG.head == \"lstm\":\n",
    "            model = CustomModel_lstm(CFG, config_path=None, pretrained=True)\n",
    "    torch.save(model.config, OUTPUT_DIR + \"config.pth\")\n",
    "    model.to(device)\n",
    "\n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p\n",
    "                    for n, p in model.model.named_parameters()\n",
    "                    if not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"lr\": encoder_lr,\n",
    "                \"weight_decay\": weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p\n",
    "                    for n, p in model.model.named_parameters()\n",
    "                    if any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"lr\": encoder_lr,\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "                \"lr\": decoder_lr,\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "\n",
    "    optimizer_parameters = get_optimizer_params(\n",
    "        model,\n",
    "        encoder_lr=CFG.encoder_lr,\n",
    "        decoder_lr=CFG.decoder_lr,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "    )\n",
    "    optimizer = AdamW(\n",
    "        optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        if cfg.scheduler == \"linear\":\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer,\n",
    "                num_warmup_steps=cfg.num_warmup_steps,\n",
    "                num_training_steps=num_train_steps,\n",
    "            )\n",
    "        elif cfg.scheduler == \"cosine\":\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer,\n",
    "                num_warmup_steps=cfg.num_warmup_steps,\n",
    "                num_training_steps=num_train_steps,\n",
    "                num_cycles=cfg.num_cycles,\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
    "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "\n",
    "    best_score = -np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        if epoch < 3:\n",
    "            # train\n",
    "            best_score = train_fn(\n",
    "                fold,\n",
    "                train_loader,\n",
    "                valid_loader,\n",
    "                valid_labels,\n",
    "                valid_loader2,\n",
    "                valid_labels2,\n",
    "                model,\n",
    "                criterion,\n",
    "                optimizer,\n",
    "                epoch,\n",
    "                scheduler,\n",
    "                device,\n",
    "                best_score,\n",
    "            )\n",
    "\n",
    "    predictions = torch.load(\n",
    "        OUTPUT_DIR + f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "    )[\"predictions\"]\n",
    "    valid_folds[\"pred\"] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return valid_folds"
   ],
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1714100540295,
     "user": {
      "displayName": "落合広則",
      "userId": "03558466850887896673"
     },
     "user_tz": -540
    },
    "id": "Usz07NWRTxPa",
    "execution": {
     "iopub.status.busy": "2024-07-14T01:53:12.058954Z",
     "iopub.execute_input": "2024-07-14T01:53:12.05931Z",
     "iopub.status.idle": "2024-07-14T01:53:12.084634Z",
     "shell.execute_reply.started": "2024-07-14T01:53:12.059278Z",
     "shell.execute_reply": "2024-07-14T01:53:12.083778Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    def get_result(oof_df):\n",
    "        labels = oof_df[CFG.target_cols2].values\n",
    "        preds = oof_df[\"pred\"].values\n",
    "        score = get_score(labels, preds)\n",
    "        labels = oof_df.loc[oof_df.flag == 1, CFG.target_cols2].values\n",
    "        preds = oof_df.loc[oof_df.flag == 1, \"pred\"].values\n",
    "        score2 = get_score(labels, preds)\n",
    "        LOGGER.info(f\"Score: {score:<.4f} Score2: {score2:<.4f}\")\n",
    "\n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(train, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df)\n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        oof_df.to_pickle(OUTPUT_DIR + \"oof_df.pkl\")"
   ],
   "metadata": {
    "id": "ys3wBaWQTy4g",
    "outputId": "b022c805-9b44-4697-e1d9-bd9f5a1066f5",
    "execution": {
     "iopub.status.busy": "2024-07-14T01:57:25.715937Z",
     "iopub.execute_input": "2024-07-14T01:57:25.716644Z",
     "iopub.status.idle": "2024-07-14T01:57:42.745789Z",
     "shell.execute_reply.started": "2024-07-14T01:57:25.716585Z",
     "shell.execute_reply": "2024-07-14T01:57:42.744351Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
