Пайплайн для обучения и инференса модели для автоматического выставления оценок
по написанным эссе.

# Automated Essay Scoring

### Давыдов Михаил

## Постановка задачи

Проблема -- учителя тратят слишком много времени на проверку эссе студентов и
школьников. Цель -- создать систему автоматического выставления оценок для эссе
школьников с помощью машинного обучения.

## Формат входных и выходных данных

На входе 3 файла: train.csv - эссе и их оценки, использумемые как данные для
тренировки. 3 колонки:

1. essay_id - уникальный id для эссе
2. full_text - полный текст эссе
3. score - честная оценка для эссе по шкале от 1 до 6

test.csv - эссе, использумеые как тестовые данные. Такие же поля, как в
train.csv, но без поля 'score'

sample_submission.csv - файл для сдачи в корректном формате. 2 колонки:

1. essay_id - уникальный id для эссе
2. score - предсказанная честная оценка для эссе по шкале от 1 до 6

Исходные оценки ставились по
[этим критериям](https://storage.googleapis.com/kaggle-forum-message-attachments/2733927/20538/Rubric_%20Holistic%20Essay%20Scoring.pdf).

## Метрики

Ответы оцениваются по метрике `quadratic weighted kappa`, показывающая степень
согласия между двумя оценками. Обычно метрика меняется от 0 (случайное согласие)
до 1 (полное согласие). Если степень согласия между метриками меньше, чем для
случайного, то оценка может уйти ниже 0.

`quadratic weighted kappa` вычисляется так: Сначала создается матрица $O$
размера $N \times N$, причем $O_{i,j}$ отвечает за количество эссе с изначальной
оценкой $i$ и получивших предсказание оценки $j$. Матрица весов $w$ размера
$N \times N$ создается по формуле:

$$
w_{i, j} = \frac{(i − j)^2}{(N − 1)^2}
$$

Матрица $E$ размера $N \times N$ вычисляется так: сначала создается вектора $u$
и $v$, у первого на $i$-ом месте стоит количество оценок $i$ в тестовой выборке,
$v$ -- так же, но для предсказанных значений. Далее $E = u \otimes v$,
нормализованное так, чтобы суммы элементов у $E$ и $O$ были одинаковыми.

`quadratic weighted kappa` из этих матриц вычисляется как:

$$
\kappa = 1 - \frac{\sum_{i, j}w_{i,j}O_{i,j}}{\sum_{i, j}w_{i,j}E_{i,j}}
$$

## Валидация

Стратегия: мы пользуемся Multilabel Stratified K‑Fold из пакета
`iterstrat.ml_stratifiers`. Стратификация идёт сразу по двум признакам‑меткам:
`prompt_name` (тематика эссе) + `score` (итоговый балл). Благодаря этому каждая
из K фолдов отражает исходное распределение тем и оценок, то есть метрика
CV ≈ LB.

```python
mskf = MultilabelStratifiedKFold(
        n_splits=cfg.n_folds,
        shuffle=True,
        random_state=42)          # ← фиксируем сид
```

Двойная валидация: Для каждого фолда формируются две выборки

| Назначение | Флаг `flag` | Где используется                           |
| ---------- | ----------- | ------------------------------------------ |
| valid A    | любая       | лог-контроль (loss)                        |
| valid B    | 0→A / 1→B   | именно по ней отбирается «best checkpoint» |

Воспроизводимость:

глобальный сид задаётся функцией `seed_everything(cfg.seed)` – она
фиксирует `random` / `numpy` / `torch` и флаг `PYTHONHASHSEED`;

`deterministic=False` в Lightning → можно включить
`torch.backends.cudnn.deterministic = True`, если нужен абсолютный бит‑в‑бит
результат;

все пути к артфактам (сплиты, чекпойнты) записываются на диск, поэтому полный
rerun от тех же файлов даёт идентичный CV.

## Данные

Все данные лежат в папке "learning-agency-lab-automated-essay-scoring-2" и
состоят из файлов:

1. train.csv -- описано выше
2. test.csv -- описано выше
3. sample_submission.csv -- описано выше

Все эти 3 файла можно найти
[в столбце "Дата"](https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/data)
соревнования kaggle.

4. [persuade_2.0_human_scores_demo_id_github.csv](https://www.kaggle.com/datasets/nbroad/persaude-corpus-2?select=persuade_2.0_human_scores_demo_id_github.csv)
   -- файл для разметки данных на те, которые принадлежат к одной известной теме
   (есть промпт), и данные, у которых нет промптов.

## Основная модель

| Этап                        | Что делаем                                                                                                                                                                                                                                                                             | Ссылки / детали                                |
| --------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------- |
| Пред-добучение (MLM)        | Берём пред-тренированный DeBERTa v3 base/large [MS FT-код] и доучиваем его на «сырых» текстах задач датасета с задачей Masked-LM; длина блока — `block_size` в конфиге.                                                                                                                | `deberta_tuning.py`                            |
| Stage 1 (A + B, монитор B)  | _Backbone_ — зафиксированный чекпоинт из шага MLM;<br>_Head_ — один из трёх вариантов:<br> – `mean_pooling` (нейтральный baseline)<br> – `attention` (взвешенная сумма)<br> – `lstm` (двухслойная Bi-LSTM поверх токенов).<br>_Loss_ — `BCEWithLogitsLoss`, т.к. регрессируем в [0,1]. | `lightning_modules.py` + `model.py`            |
| Stage 2 (B-only, монитор A) | Инициализируем тем же чекпоинтом, но тренируем только на флагах 1 и валидируем на A, чтобы не переобучиться.<br>Target-smoothing: `score_s = (1 - sl_rate) * score / 5 + sl_rate * oof_pred`.                                                                                          | `modify_train_data.load_pickle_data`           |
| Оптимизация                 | `AdamW`, весовой декей для ненормализуемых параметров; планер — linear или cosine с warm-up, шаг — каждый батч.<br>AMP (`precision=16`) на GPU.                                                                                                                                        | `configure_optimizers()`                       |
| Ensemble / blending         | K фолдов × N голов = N · K моделей.<br>OOF-предсказания сохраняются, веса ансамбля подбираются Nelder–Mead (scipy) с оптимизацией QWK.                                                                                                                                                 | `inference/oof.py`, `inference/nelder_mead.py` |
| Инференс                    | Чекпоинт Stage 2 → `Trainer.predict(...)` → усреднение по фолдам → взвешенная сумма по моделям.                                                                                                                                                                                        | `inference_lightning.py`                       |

- DeBERTa v3 base — microsoft/deberta‑v3‑base
- DeBERTa v3 large — microsoft/deberta‑v3‑large
- Multilabel
  Stratified K‑Fold — https://github.com/trent-b/iterative-stratification

## Внедрение

Модель можно будет запускать для оценки имеющихся текстов. Для этого все
чекпоинты модели и все веса модели должны быть на сервере, из которого будет
запускаться модель для инференса. Будет использоваться Triton.

## План реализации проекта

- [x] Выбрать проект
- [x] Разобраться с conda и poetry
- [x] Разделить проект по функциям
- [x] Добавить средства поддержки quality tools
- [x] Научить запускать проект как локально, так и в Kaggle
- [x] Заставить проект работать
- [x] Первичный рефакторинг
- [x] Отдебажить конфигурации с гидрой
- [x] Разобраться с GroupKFold
- [x] Убрать все ворнинги
- [x] Отрефакторить submission
- [x] Добавить MLFlow
- [x] Дописать readme.md
- [x] Изменить поведение логгера
- [x] Добавить Lightning, add mlflow again
- [x] Добавить возможность контроля выбранных частей кода (без файнтюна или
      только инференс) через Fire.
- [x] Выделить расчет лучших весов в отдельный код и дать возможность запускать
      с уже имеющимися весами.
- [x] Добавить аннотации типов
- [x] Написать документацию
- [x] Еще один рефакторинг -- пересмотр своего кода
- [ ] Добавить dvc
- [ ] Переписать README.md
- [ ] Разделить код на train и infer
- [ ] Добавить сохранение моделей через TensorRT (или TorchScript)
- [ ] Добавить Triton для инференса
- [ ] Добавить поддержку kaggle и kaggle/tmp
- [ ] Запустить на всех данных
- [ ] Написать тесты
