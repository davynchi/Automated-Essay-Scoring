# base.yaml (equivalent of CFG class)
debug: False
apex: True
print_freq: 100
num_workers: 4
scheduler: "cosine" # ['linear', 'cosine']
batch_scheduler: True
num_cycles: 0.5
num_warmup_steps: 0
epochs: 1 # Было 5
encoder_lr: 1e-5
decoder_lr: 1e-5
min_lr: 1e-6
eps: 1e-6
betas: [0.9, 0.999]
batch_size: 4
model_config:
  attention_dropout: 0.0
  attention_probs_dropout_prob: 0.0
  hidden_dropout: 0.0
  hidden_dropout_prob: 0.0
target_size: 1
target_cols: "score"
target_cols2: ["score"]
target_cols3: ["score_s"]
# max_len: 1024
weight_decay: 0.01
gradient_accumulation_steps: 1
max_grad_norm: 1000
# n_fold: 6 -- так было
trn_fold: [0, 1] # trn_fold = [0] -- так было
freeze_layer: 9
# head: "mean_pooling"  # 'mean_pooling' 'attention' 'lstm'
# sl: False  # This parameter changes in the code, change the behaviour!
sl_rate: 0.2
train: True
flag: 0
# trn_fold = [0, 1, 2, 3, 4, 5] # -- так было в CFG во 2ом ноутбуке
# Тут еще был sl --  переправь логику в файле!
